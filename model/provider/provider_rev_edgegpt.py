from model.provider.provider import Provider
from EdgeGPT import Chatbot, ConversationStyle
import json
import os
from util import general_utils as gu


class ProviderRevEdgeGPT(Provider):
    def __init__(self):
        self.busy = False
        self.wait_stack = []
        with open('./cookies.json', 'r') as f:
            cookies = json.load(f)
        self.bot = Chatbot(cookies=cookies)

    def is_busy(self):
        return self.busy

    async def forget(self):
        try:
            await self.bot.reset()
            return True
        except BaseException:
            return False
        
    async def text_chat(self, prompt, platform = 'none'):
        if self.busy:
             return
        self.busy = True
        resp = 'err'
        err_count = 0
        retry_count = 5
        
        while err_count < retry_count:
            try:
                resp = await self.bot.ask(prompt=prompt, conversation_style=ConversationStyle.creative)
                # print("[RevEdgeGPT] "+str(resp))
                if 'messages' not in resp['item']:
                    await self.bot.reset()
                msj_obj = resp['item']['messages'][len(resp['item']['messages'])-1]
                reply_msg = msj_obj['text']
                if 'sourceAttributions' in msj_obj:
                    reply_source = msj_obj['sourceAttributions']
                else:
                    reply_source = []
                if 'throttling' in resp['item']:
                    throttling = resp['item']['throttling']
                    # print(throttling)
                else:
                    throttling = None
                if 'I\'m sorry but I prefer not to continue this conversation. I\'m still learning so I appreciate your understanding and patience.' in reply_msg:
                    self.busy = False
                    return '', 0
                if reply_msg == prompt:
                    # resp += '\n\nÂ¶ÇÊûú‰Ω†Ê≤°ÊúâËÆ©ÊàëÂ§çËø∞‰Ω†ÁöÑËØùÔºåÈÇ£‰ª£Ë°®ÊàëÂèØËÉΩ‰∏çÊÉ≥Âíå‰Ω†ÁªßÁª≠Ëøô‰∏™ËØùÈ¢ò‰∫ÜÔºåËØ∑ËæìÂÖ•resetÈáçÁΩÆ‰ºöËØùüò∂'
                    await self.forget()
                    err_count += 1
                    continue
                if reply_source is None:
                    # ‰∏çÊÉ≥Á≠îÂ§ç
                    return '', 0
                else:
                    if platform != 'qqchan':
                        index = 1
                        if len(reply_source) > 0:
                            reply_msg += "\n\n‰ø°ÊÅØÊù•Ê∫ê:\n"
                        for i in reply_source:
                            reply_msg += f"[{str(index)}]: {i['seeMoreUrl']} | {i['providerDisplayName']}\n"
                            index += 1
                if throttling is not None:
                    if throttling['numUserMessagesInConversation'] == throttling['maxNumUserMessagesInConversation']:
                        # ËææÂà∞‰∏äÈôêÔºåÈáçÁΩÆ‰ºöËØù
                        await self.forget()
                    if throttling['numUserMessagesInConversation'] > throttling['maxNumUserMessagesInConversation']:
                        await self.forget()
                        err_count += 1
                        continue
                    reply_msg += f"\n‚åà{throttling['numUserMessagesInConversation']}/{throttling['maxNumUserMessagesInConversation']}‚åã"
                break
            except BaseException as e:
                gu.log(str(e), level=gu.LEVEL_WARNING, tag="RevEdgeGPT")
                err_count += 1
                if err_count >= retry_count:
                        self.busy = False
                        raise e
                gu.log("ËØ∑Ê±ÇÂá∫Áé∞‰∫Ü‰∏Ä‰∫õÈóÆÈ¢ò, Ê≠£Âú®ÈáçËØï„ÄÇÊ¨°Êï∞"+str(err_count), level=gu.LEVEL_WARNING, tag="RevEdgeGPT")
        self.busy = False
        
        # print("[RevEdgeGPT] "+str(reply_msg))
        return reply_msg, 1
    
